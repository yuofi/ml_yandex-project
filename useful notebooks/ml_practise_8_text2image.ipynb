{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6975837-a202-453a-a5b3-7caa1fe6da56",
   "metadata": {},
   "source": [
    "#  **Практическое занятие №8. Text2image модели. Основные архитектуры**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "250bc646-9b8b-4ac8-a1d0-40433636b0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e9e025-d52e-48bd-a91d-9a29d255661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00218dd2-3130-4377-96e0-7ddcc3662bb4",
   "metadata": {},
   "source": [
    "## Inception Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf61096-3d36-4495-86b6-e4dcf6ee8ac5",
   "metadata": {},
   "source": [
    "Документация по Inception Score на torch https://pytorch.org/ignite/generated/ignite.metrics.InceptionScore.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9876704-2f83-44bf-8f15-d275445a27a1",
   "metadata": {},
   "source": [
    "### Применяем Inception v3 к конкретному изображению"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58aeb7e8-d14f-4a30-8f04-6115c51636d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.10.0', 'inception_v3', pretrained=True)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee599e57-7a3b-445f-812c-a7a14d45be0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "import torchshow as ts\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ad4c71-a9c4-49f3-ad18-5b07532e7325",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(url):\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return PIL.Image.open(io.BytesIO(resp.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba92b7ae-ef63-4976-8b79-b849d167cd63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    input_tensor = transform(input_image)\n",
    "    #print(input_tensor.shape)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    #print(input_batch.shape)\n",
    "    return input_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910d49de-1b6f-43b8-9b66-813bf5c83013",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = download_image('https://assets.bwbx.io/images/users/iqjWHBFdfxIU/iKIWgaiJUtss/v2/1000x-1.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e14fc9-0a4c-4add-8755-d4ed1854e74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674edd5-07b1-4304-80e1-54a3ed96657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch = preprocess(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584d850a-eeed-4907-8664-63feaa846969",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3b00c0-12ea-4213-9c1c-f2817b8c50a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(input_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6b594b-f0dc-4bb3-b29d-26560d8071bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4396ee43-9c39-4194-b63d-bf73cb3bea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = torch.nn.functional.softmax(output[0], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98537b10-a6af-439c-8a80-59a17274530e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa669839-91f5-4751-9d68-bf521532d175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1000), probabilities)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee90908-05c7-4492-801a-4a1f72bc2a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d5c12e-0097-46f0-bd0f-4600170de829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a7feff1-7299-4971-9591-07598f6b4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "    categories = [s.strip() for s in f.readlines()]\n",
    "\n",
    "top5_prob, top5_catid = torch.topk(probabilities, 5)\n",
    "for i in range(top5_prob.size(0)):\n",
    "    print(categories[top5_catid[i]], top5_prob[i].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43dd7b8-3551-4fbf-88a3-f384383237f8",
   "metadata": {},
   "source": [
    "### Посчитаем Inception Score на данных из CIFAR-10 (как будто эти картинки выдал генератор)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343382fd-eaa4-421b-9a53-8d540d285ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar_transform = transforms.Compose([\n",
    "        transforms.Resize(299),\n",
    "        transforms.CenterCrop(299),\n",
    "        transforms.ToTensor(),\n",
    "        #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cd1810-b4d7-4c4c-9280-21c4766ff91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision import transforms, datasets\n",
    "import torchshow as ts\n",
    "import torchvision\n",
    "\n",
    "import io\n",
    "import requests\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1d1ed6-de1d-4e30-bd1c-b57bf3db904b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install torchvision==0.15.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf40699-61e5-49aa-9b55-7a1bf7f49611",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_testset = torchvision.datasets.CIFAR10(root='cifar', train=False, download=True, transform=cifar_transform)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96073960-fc0f-46f2-bfca-ca3b3b1cfa21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(15,4))\n",
    "\n",
    "for i in range(20):\n",
    "    plt.subplot(2, 10, i + 1)\n",
    "    plt.imshow(cifar10_testset[i][0].permute(1, 2, 0) \n",
    "              )\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(classes[cifar10_testset[i][1]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0df1f5-8b33-45a3-88ae-8bdcd5844865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "from ignite.engine import *\n",
    "from ignite.handlers import *\n",
    "from ignite.metrics import *\n",
    "from ignite.utils import *\n",
    "from ignite.contrib.metrics.regression import *\n",
    "from ignite.contrib.metrics import *\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d29f2-a323-4c7e-8db4-7a1e0b4590b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ignite.engine import Engine\n",
    "from ignite.metrics import InceptionScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68da5b22-5ca9-4d57-ba47-6ad3003a2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inceptor = nn.Sequential(\n",
    "    model,\n",
    "    nn.Softmax(1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd977b2-27db-412d-8d64-cf85aedfff4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_function(engine, batch):\n",
    "    # ...\n",
    "    return batch\n",
    "\n",
    "engine = Engine(process_function)\n",
    "metric = InceptionScore(num_features=1000, feature_extractor=inceptor)\n",
    "metric.attach(engine, \"is\")\n",
    "\n",
    "dataloader = DataLoader(cifar10_testset, batch_size=100, shuffle=True)\n",
    "data, labels = next(iter(dataloader))\n",
    "\n",
    "# ...\n",
    "state = engine.run([data], 1)\n",
    "print(f\"InceptionScore: {state.metrics['is']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1499ff9-0941-41fb-96a9-1c3959861267",
   "metadata": {},
   "source": [
    "### Автоэнкодер"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224fc813-e3de-4290-9725-1afa0bf5e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchshow as ts\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a31e3f-d79f-48fb-8c66-f44b9140dddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_val = datasets.MNIST(root='mnist', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_train, mnist_val = random_split(mnist_train_val, [0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73401f86-767e-4d18-81b5-0144e009ece8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example\n",
    "img, cls = mnist_train_val[1]\n",
    "ts.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2e4efe-644e-4910-bb80-d0777c1c8a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5a59ad-8119-4ebd-a628-d6de419982cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=1024, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(np.prod(img_shape), hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, latent_dim)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(hidden_dim, np.prod(img_shape)),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Unflatten(1, img_shape)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        return self.encoder(x)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = self.encoder(x)\n",
    "        y = self.decoder(z)\n",
    "        return y\n",
    "    \n",
    "    def process(self, x):\n",
    "        return self(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df14c2da-96d6-4a8c-93d9-ec5475611cb0",
   "metadata": {},
   "source": [
    "Напишем вспомогальные функции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26f1d6-c4d3-4372-a74e-257f4e7a7f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# одна эпоха обучения\n",
    "def run_epoch(ae, opt, loss, dataloader, is_train=True):\n",
    "    ae.train(is_train)\n",
    "    total_loss = 0.0\n",
    "    with torch.set_grad_enabled(is_train):\n",
    "        for x, _ in tqdm(dataloader):\n",
    "            x = x.to(device)\n",
    "            l = loss(x, ae(x))\n",
    "            if (is_train):\n",
    "                opt.zero_grad()\n",
    "                l.backward()\n",
    "                opt.step()\n",
    "            total_loss += l.item()\n",
    "    return total_loss / len(dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537e2524-b942-472f-999e-6fb4d77fff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисовка лосса\n",
    "def plot_loss(loss, title, num_epochs):\n",
    "    plt.title(title)\n",
    "    plt.plot(loss)\n",
    "    plt.grid()\n",
    "    plt.xticks(np.arange(num_epochs))\n",
    "\n",
    "def plot_losses(train, val, num_epochs):\n",
    "    plt.figure(figsize=(16, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plot_loss(train, f'Train Loss = {train[-1]}', num_epochs)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plot_loss(val, f'Val Loss = {val[-1]}', num_epochs)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf9f8d1-5055-4ded-acfd-afb9f7838e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# отрисовка изображений - реальных и после автоэнкодера\n",
    "def show_examples(ae, dataset, size):\n",
    "    ae.eval()\n",
    "    with torch.no_grad():\n",
    "        idxs = np.random.randint(0, len(dataset), size)\n",
    "        x = torch.stack([dataset[i][0] for i in idxs]).to(device)\n",
    "        y = ae.process(x)\n",
    "        print(\"Original images\")\n",
    "        ts.show(x, nrows=1, figsize=(12, 2))\n",
    "        print(\"Reconstructed\")\n",
    "        ts.show(y, nrows=1, figsize=(12, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7d4134-83fe-4c51-829e-3093e2575e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def run_train_loop(ae, opt, loss, train_loader, val_loader, num_epochs, ex_size):\n",
    "    train_hist = []\n",
    "    val_hist = []\n",
    "    for e in range(num_epochs):\n",
    "        print(\"Trainin...\")\n",
    "        train_loss = run_epoch(ae, opt, loss, train_loader)\n",
    "        train_hist.append(train_loss)\n",
    "        print(\"Validating...\")\n",
    "        val_loss = run_epoch(ae, opt, loss, val_loader, is_train=False)\n",
    "        val_hist.append(val_loss)\n",
    "        clear_output()\n",
    "        plot_losses(train_hist, val_hist, num_epochs)\n",
    "        show_examples(ae, val_loader.dataset, ex_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9995fcde-ea16-4c93-8307-a4a226abd158",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "lat_dim = 8 # размерность скрытого пространства\n",
    "ex_size = 8 # число примеров для отрисовки\n",
    "\n",
    "train_loader = DataLoader(mnist_train, batch_size)\n",
    "val_loader = DataLoader(mnist_val, batch_size)\n",
    "\n",
    "sae = SimpleAutoEncoder(lat_dim).to(device)\n",
    "sae_opt = optim.Adam(sae.parameters())\n",
    "sae_loss = nn.MSELoss(reduction='sum')\n",
    "\n",
    "run_train_loop(sae, sae_opt, sae_loss,\n",
    "               train_loader, val_loader, num_epochs, ex_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fab1ae-bb5f-434b-9bbb-51b96447fcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = next(iter(val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e346fe6-791f-46fc-b483-2066993534b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = data[0]\n",
    "sae.encode(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aa05d3-bc45-4a7e-8fa1-402f535dfa6a",
   "metadata": {},
   "source": [
    "Посмотрим, как выглядит скрытое пространство автоэнкодера:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad946df-62f9-4b26-b0e8-cae208549a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_enc_dist(ae, xi, yi, dataset, size):\n",
    "    idxs = np.random.randint(0, len(dataset), size)\n",
    "    ae.eval()\n",
    "    with torch.no_grad():\n",
    "        z = ae.encode(torch.stack([dataset[i][0] for i in idxs]).to(device))\n",
    "    x = z[:,xi].cpu().numpy()\n",
    "    y = z[:,yi].cpu().numpy()\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.scatter(x, y, c = [dataset[i][1] for i in idxs])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d931065-6753-4e4f-87ef-0cc35df8c8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_enc_dist(sae, 0, 1, mnist_val, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032546e-1e37-460c-804f-f4af985dbecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleVariationalAutoEncoder(nn.Module):\n",
    "    def __init__(self, latent_dim, img_shape=(1, 28, 28)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder_common = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(np.prod(img_shape), 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU()\n",
    "        )\n",
    "        self.encoder_m = nn.Linear(512, latent_dim)\n",
    "        self.encoder_s = nn.Linear(512, latent_dim)\n",
    "\n",
    "        self.N = torch.distributions.Normal(0, 1)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Linear(512, np.prod(img_shape)),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Unflatten(1, img_shape)\n",
    "        )\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder_common(x)\n",
    "        m = self.encoder_m(x)\n",
    "        s = torch.exp(self.encoder_s(x))\n",
    "        return m + s * self.N.sample(m.shape)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder_common(x)\n",
    "        m = self.encoder_m(x)\n",
    "        s = torch.exp(self.encoder_s(x))\n",
    "        z = m + s * self.N.sample(m.shape)\n",
    "        y = self.decoder(z)\n",
    "        return y, m, s\n",
    "\n",
    "    def process(self, x):\n",
    "        return self(x)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff15fa4-db49-49a0-82b1-ee28b1261c19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ebdb9-e83d-4f0e-8883-6afe465f5860",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
